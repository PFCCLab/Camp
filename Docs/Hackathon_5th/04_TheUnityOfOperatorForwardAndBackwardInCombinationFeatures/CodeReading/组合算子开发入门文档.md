## 1. 组合机制涉及文件及作用
### 1.1. 前向下沉需要修改的文件
* `paddle/fluid/pir/dialect/op_generator/decomp_interface_gen_op_list.py`: 组合机制前向算子注册文件。*decomp_interface_declare_gen_op_list* 和 *decomp_interface_implementation_gen_op_list* 结构中增加目标算子，可以自动在 *pd_op.h* 和 *op_decomp.cc* 文件中生成该算子的前向拆解前置代码逻辑。（建议以字母序添加算子，减少代码冲突）

* `paddle/fluid/primitive/composite/composite.h`: 算子前向组合机制逻辑实现文件，在该文件中编写算子的前向拆解逻辑。

* `Paddle/test/legacy_test/*`: 算子组合机制测试文件，根据算子的不同，测试文件名字有所差异。部分算子的测试文件在 *test_activation_op.py* 文件中，大部分以 *test_(op name)_op.py* 命名。在算子的测试文件中，需要关注 *test_check_output()* 函数，为该函数下属方法增加 *check_prim_pir=True* 选项。

### 1.2. 反向迁移需要修改的文件
* `Paddle/paddle/fluid/primitive/codegen/gen.py`: 组合机制反向算子注册文件。根据算子类型将算子添加到 *UNARY_PRIM_VJP_OPS*、*BINARY_PRIM_VJP_OPS*、*OTHER_PRIM_VJP_OPS*、*CUSTOM_VJP* 中的某一个结构中，可自动在 *generated_vjp.cc* 中生成该算子的反向拆解前置代码逻辑。

* `Paddle/paddle/fluid/primitive/rule/vjp/details.h`: 算子反向组合机制逻辑实现文件，在该文件中编写算子的反向拆解逻辑。

* `Paddle/test/legacy_test/*`: 算子组合机制测试文件，根据算子的不同，测试文件名字有所差异。部分算子的测试文件在 *test_activation_op.py* 文件中，大部分以 *test_(op name)_op.py* 命名。在算子的测试文件中，需要关注 *test_check_grad()* 函数，为该函数下属方法增加 *check_prim_pir=True* 选项。

### 1.3. 其他文件

* `/Paddle/python/paddle/incubate/autograd/composite_rules.py`: 旧IR下组合算子的前向拆解规则，使用 python 实现，在 composite.h 实现算子拆解逻辑时，可以参考该文件中的算子拆解逻辑。
* `/mnt/Paddle/paddle/fluid/prim/api/composite_backward/composite_backward_api.h`: 旧IR下组合算子的反向拆解规则，使用c++实现，在 details.h 中实现时，可以参考（可以复制代码到details.h, 再修改错误）

* `/mnt/Paddle/build/paddle/fluid/pir/dialect/operator/ir/op_decomp.cc`: 组合机制前向拆解的前置代码（调用composite.h），可以检查算子前向拆解的组合机制代码生成是否正确
* `/mnt/Paddle/build/paddle/fluid/pir/dialect/operator/ir/pd_op.h`: 组合机制前向拆解的前置代码（op_decomp.cc 的类定义），可以检查算子前向拆解的组合机制代码生成是否正确
* `/mnt/Paddle/build/paddle/fluid/primitive/rule/vjp/generated/generated_vjp.cc`: 组合机制反向拆解的前置代码（调用details.h），可以检查算子反向拆解的组合机制代码生成是否正确

* `/mnt/Paddle/build/paddle/fluid/primitive/primitive/primitive.h`: 基础算子代码实现，即可将目标算子拆解为该文件中的算子的组合形式
* `/mnt/Paddle/paddle/fluid/primitive/primitive.yaml`: 基础算子配置文件，包含所有基础算子名称，用来生成 primitive.h
* `/mnt/Paddle/paddle/phi/api/yaml/op_compat.yaml`: 算子配置文件，可用来查看部分 算子 与 算子别名 对照关系
* `/mnt/Paddle/paddle/fluid/pir/dialect/operator/ir/ops_backward.yaml`: 反向算子函数格式配置文件，用来生成 generated_vjp.cc

## 2. 组合机制前向下沉开发流程 -- 以 relu 算子为例
![img](https://github.com/kevincheng2/Camp/blob/kevincheng2/WeeklyReport/Docs/04_TheUnityOfOperatorForwardAndBackwardInCombinationFeatures/imgs/forward_prim.png)
### 2.1. 算子注册
打开 *decomp_interface_gen_op_list.py* 文件，在 `decomp_interface_declare_gen_op_list` 和 `decomp_interface_implementation_gen_op_list` 中注册新增 relu 算子。
```
## /mnt/Paddle/paddle/fluid/pir/dialect/op_generator/decomp_interface_gen_op_list.py

# come into effect in generated file pd_op.h
# manual decomp interface declare are located in manual_op.h
decomp_interface_declare_gen_op_list = [
    "add_n",
    "pow",
    "relu",
    "rsqrt",
    "sigmoid",
    "silu",
    "softmax",
    "sqrt",
    "squeeze",
    "stack",
    "unsqueeze",
]

# come into effect in generated file op_decomp.cc
# manual decomp interface implementation are located in manual_op_decomp.cc
decomp_interface_implementation_gen_op_list = [
    "add_n",
    "pow",
    "relu",
    "rsqrt",
    "sigmoid",
    "silu",
    "softmax",
    "sqrt",
    "squeeze",
    "stack",
    "unsqueeze",
]
```

### 2.2. 算子前向拆解规则开发
在 `paddle/fluid/primitive/composite/composite.h` 文件中，新增 *relu_decomop()* 函数（参考*op_decomp.cc*文件中自动生成的函数名、参数、返回值），参考 *composite_rules.py* 中python实现，在该函数中实现算子的拆解规则
```
// /mnt/Paddle/paddle/fluid/primitive/composite/composite.h

template <typename T>
Tensor relu_decomp(const Tensor& x) {
  return maximum<T>(x, full<T>(common::vectorize(x.dims()), 0.0, x.dtype()));
}
```

### 2.3. 测试
在文件夹`Paddle/test/legacy_test/test_activation_op.py`中找到算子对应的测试文件，在 *test_check_output* 中新增 *check_prim_pir=True* 测试
打开对应文件夹，执行命令  `python test_activation_op.py TestRelu.test_check_output` 指定 *test_activation_op.py* 文件中的 *TestRelu* 测试案例中的 *test_check_output* 函数，查看运行结果
```
# /mnt/Paddle/test/legacy_test/test_activation_op.py

class TestRelu(TestActivation):
    def setUp(self):
        self.op_type = "relu"
        self.python_api = paddle.nn.functional.relu
        self.prim_op_type = "comp"
        self.public_python_api = paddle.nn.functional.relu
        self.init_dtype()
        self.init_shape()
        self.if_enable_cinn()
        np.random.seed(1024)
        x = np.random.uniform(-1, 1, self.shape).astype(self.dtype)
        # The same reason with TestAbs
        x[np.abs(x) < 0.005] = 0.02
        out = np.maximum(x, 0)
        self.inputs = {'X': x}
        self.outputs = {'Out': out}
        self.convert_input_output()
    def test_check_grad(self):
        if self.dtype == np.float16:
            return
        self.check_grad(
            ['X'], 'Out', check_prim=True, check_pir=True
        )
    def test_check_output(self):
        self.check_output(check_prim=True, check_pir=True, check_prim_pir=True)
    def if_enable_cinn(self):
        pass
```

*NOTE*：
部分测试文件中，并没有支持组合机制测试，需要添加部分配置。
可以检查 `def setUp(self):` 中是否有 `self.prim_op_type`、`self.public_python_api` 配置参数。
```
// 表示组合机制拆解类型。其中，comp 表示拆前向和反向，prim 表示只拆反向
self.prim_op_type = "comp"

// 指定python使用的公共API ，可以参考 self.python_api 字段。
self.public_python_api = paddle.nn.functional.relu
```

## 3. 组合机制反向迁移开发流程 -- 以 sum 算子为例
![img](https://github.com/kevincheng2/Camp/blob/kevincheng2/WeeklyReport/Docs/04_TheUnityOfOperatorForwardAndBackwardInCombinationFeatures/imgs/backward_prim.png)

### 3.1. 算子注册
在 `Paddle/paddle/fluid/primitive/codegen/gen.py` 文件中的 `OTHER_PRIM_VJP_OPS` 中新增 `sum_grad` 算子
添加规则：
- 基础算子根据算子输入和输出分类，分别插入到 `UNARY_PRIM_VJP_OPS、BINARY_PRIM_VJP_OPS、OTHER_PRIM_VJP_OPS` 中
- 非基础算子插入到 `CUSTOM_VJP` 中
*NOTE*：
- 基础算子和非基础算子的区分可以参考 `/mnt/Paddle/paddle/fluid/primitive/primitive.yaml` 文件。
- 建议以字母序注册 `op_name` , 减少代码冲突。

```
# /mnt/Paddle/paddle/fluid/primitive/codegen/gen.py

# 基础算子注册 list， 根据算子特性添加到对应位置
# prim op with one input and one output, with no attribute
UNARY_PRIM_VJP_OPS = [
    'abs_grad',
    'erf_grad',
    'exp_grad',
    'floor_grad',
    'log_grad',
    'sin_grad',
    'cos_grad',
    'tanh_grad',
]

# prim op with two inputs and one output, with no attribute
BINARY_PRIM_VJP_OPS = [
    'add_grad',
    'divide_grad',
    'subtract_grad',
    'multiply_grad',
    'elementwise_pow_grad',
    'maximum_grad',
]

OTHER_PRIM_VJP_OPS = [
    'assign_grad',
    'cumsum_grad',
    'sum_grad',
    'cast_grad',
    'reshape_grad',
    'roll_grad',
    'split_grad',
    'transpose_grad',
    'concat_grad',
    'expand_grad',
    'gather_grad',
    'gather_nd_grad',
    'pad_grad',
    'prod_grad',
]

# 非基础算子注册 list
CUSTOM_VJP = [
    'dropout_grad',
    'gelu_grad',
    'hardswish_grad',
    'instance_norm_grad',
    'layer_norm_grad',
    'leaky_relu_grad',
    'silu_grad',
    'softmax_grad',
    'sqrt_grad',
]  # custom vjp list of composite op
```

### 3.2 算子反向拆解规则开发
在 `Paddle/paddle/fluid/primitive/rule/vjp/details.h` 文件中新增 `sum_grad()` 函数 ，在该函数中实现 `sum_grad` 算子的拆解规则。
```
// /mnt/Paddle/paddle/fluid/primitive/rule/vjp/details.h

template <typename T>
void sum_grad(const Tensor& x,
              const Tensor& out_grad,
              const IntArray& axis,
              bool keepdim,
              bool reduce_all,
              Tensor* x_grad) {
  if (!x_grad) {
    return;
  }
  std::vector<int64_t> x_dim = common::vectorize<int64_t>(x.dims());
  int64_t axis_size = axis.size();
  int64_t x_dim_size = x_dim.size();
  reduce_all = false;
  if (reduce_all || axis_size == 0 || axis_size == x_dim_size) {
    reduce_all = true;
  } else {
    reduce_all = false;
  }
  auto x_grad_tmp = Tensor();
  if (x_dim_size == 1) {
    x_grad_tmp = expand<T>(out_grad, IntArray(x_dim));
  } else {
    if (!keepdim) {
      auto axis_ = std::vector<int64_t>();
      if (reduce_all) {
        for (int64_t i = 0; i < x_dim_size; i++) {
          axis_.push_back(i);
        }
      } else {
        axis_ = axis.GetData();
        for (int64_t i = 0; i < axis_size; i++) {
          if (axis[i] < 0) {
            axis_[i] = axis[i] + x_dim_size;
          }
        }
      }
      auto out_grad_shape = get_unsqueeze_dims(out_grad, axis_);
      auto out_grad_ = reshape<T>(out_grad, out_grad_shape);
      x_grad_tmp = expand<T>(out_grad_, IntArray(x_dim));
    } else {
      x_grad_tmp = expand<T>(out_grad, IntArray(x_dim));
    }
  }
  set_output<T>(x_grad_tmp, x_grad);
}
```
### 3.3 测试
在文件夹 `Paddle/test/legacy_test/test_sum_op.py` 中找到算子对应的测试文件，在 `test_check_grad` 中新增 `check_prim_pir=True` 。
打开对应文件夹，执行命令  `python test_sum_op.py TestSumOp.test_check_grad` 指定 `test_sum_op.py`文件中的 `TestSumOp` 测试案例中的 `test_check_grad` 函数，查看运行结果
```
# /mnt/Paddle/test/legacy_test/test_sum_op.py

class TestSumOp(OpTest):
    def setUp(self):
        self.op_type = "sum"
        self.python_api = paddle.add_n
        self.public_python_api = paddle.add_n
        self.prim_op_type = "comp"
        self.init_kernel_type()
        self.use_mkldnn = False
        self.init_kernel_type()
        x0 = np.random.random((3, 40)).astype(self.dtype)
        x1 = np.random.random((3, 40)).astype(self.dtype)
        x2 = np.random.random((3, 40)).astype(self.dtype)
        self.inputs = {"X": [("x0", x0), ("x1", x1), ("x2", x2)]}
        y = x0 + x1 + x2
        self.outputs = {'Out': y}
        self.attrs = {'use_mkldnn': self.use_mkldnn}
        
    def init_kernel_type(self):
        self.dtype = np.float64
        
    def test_check_output(self):
        self.check_output(
            check_prim=True,
            check_cinn=True,
            check_pir=True,
        )
        
    def test_check_grad(self):
        self.check_grad(
            ['x0'],
            'Out',
            check_prim=True,
            check_cinn=True,
            check_pir=True,
            check_prim_pir=True,
        )
```

## 4. 拆解常用函数及基础算子
### 4.1 常用函数
基本函数位置通常在`/mnt/workspace/Paddle/paddle/fluid/primitive/utils/utils.h`文件中定义，包括 `static bool is_half_dtype(const DataType& dtype)、static std::vector<int64_t> get_expand_dims(const Tensor& origin,const std::vector<int64_t>& axis)` 等函数。

*示例*：
部分算子不支持 `[float16, bfloat16, uint16]` 数据类型，在计算之前需要将该数据类型转换为 `float32`， `is_half_dtype()` 用来判断该算子的类型是否符合要求，使用场景如下。(具体可查阅utils.h文件)
```
  bool need_cast = is_half_dtype(org_dtype);
  if (need_cast) {
    x_cast = cast<T>(x, phi::DataType::FLOAT32);
  }
```

*NOTE*：
 可复用的的功能建议封装成一个函数，放在 `/mnt/workspace/Paddle/paddle/fluid/primitive/utils/utils.h` 文件中。
 
### 4.2 常用基础算子
基础算子的实现位于`/mnt/Paddle/paddle/fluid/primitive/primitive/primitive.h` 文件中，在 `details.h`和 `composite.h`中实现算子拆解的时候，可以直接调用基础算子实现。
*示例*：
在 `softmax`算子拆解的过程中，`max 、exp 、 sum 、 cast、 -、 /` 皆是基础算子。(具体可查阅primitive.h文件)
```
// /mnt/Paddle/paddle/fluid/primitive/composite/composite.h

template <typename T>
Tensor softmax_decomp(const Tensor& x, const int& axis) {
  auto org_dtype = x.dtype();
  auto x_tmp = x;
  auto axis_tmp = IntArray({axis});
  bool need_cast = is_half_dtype(org_dtype);
  if (need_cast) {
    x_tmp = cast<T>(x, phi::DataType::FLOAT32);
  }
  auto max_tmp = max<T>(x_tmp, axis_tmp, true);
  auto molecular = exp<T>(x_tmp - max_tmp);
  auto res = molecular / sum<T>(molecular, axis_tmp, molecular.dtype(), true);
  if (need_cast) {
    return cast<T>(res, org_dtype);
  } else {
    return res;
  }
}
```
*NOTE*：
`Tensor` 计算过程中，基础运算符 `+、-、*、/` 都进行了重载，其对应计算规则分别对应 `对位相加、对位相减、矩阵点乘、对位相除`，在算子拆解的过程中，应优先使用运算符。

## 5. 调试程序
### 5.1 log 打印
- python 程序可以在程序中对应位置使用 print 打印 log
```
print("log")
```
- c++ 程序在程序中使用 `VLOG()` 语句进行 log 打印，想要查看某个文件中的某些 log 时，需要执行环境变量配置 `export GLOG_vmodule=file_name=log_level` 用来指定具体的 c++ 文件名，和 VLOG 级别。
  
*示例*：
比如想要打印 `generated_vjp.cc`文件中，`VLOG(4)` 的 log，可以配置环境变量 `export GLOG_vmodule=generated_vjp=4`

```
VLOG(4) << "Call Pir Decomposed backward op abs_grad";
```

### 5.2 判断算子是否拆解成功
#### 5.2.1 查看对应文件是否生成
- 前向拆解
检查`/mnt/Paddle/build/paddle/fluid/pir/dialect/operator/ir/op_decomp.cc`文件，算子对应的 `OP_NAME::Decomp()` 函数是否生成成功
- 反向拆解
检查`/mnt/Paddle/build/paddle/fluid/primitive/rule/vjp/generated/generated_vjp.cc`文件，算子对应的 `OP_NAME_VJP()` 函数中是否生成组合机制`IsBwdPrimEnabled()`判断逻辑。
*示例*：
```
// /mnt/Paddle/build/paddle/fluid/primitive/rule/vjp/generated/generated_vjp.cc
// 未生成组合机制判断逻辑

std::vector<std::vectorautolinkpaddle::Tensorautolink> acosh_vjp(const Tensor& x, const Tensor& out_grad, const std::vector<std::vector<bool>>& stop_gradients) {
  std::vector<std::vectorautolinkpaddle::Tensorautolink> vjp_res;
  for (auto arg: stop_gradients) {
    vjp_res.push_back(std::vectorautolinkpaddle::Tensorautolink(arg.size()));
  }
  auto op_res = backend::acosh_grad<LazyTensor>(x, out_grad);
  vjp_res[0][0] = op_res;
  vjp_res = ConstructVjpResultByStopGradients(vjp_res, stop_gradients);
  return vjp_res;
}
```

```
// /mnt/Paddle/build/paddle/fluid/primitive/rule/vjp/generated/generated_vjp.cc
// 生成组合机制判断逻辑

std::vector<std::vectorautolinkpaddle::Tensorautolink> abs_vjp(const Tensor& x, const Tensor& out_grad, const std::vector<std::vector<bool>>& stop_gradients) {
  std::vector<std::vectorautolinkpaddle::Tensorautolink> vjp_res;
  for (auto arg: stop_gradients) {
    vjp_res.push_back(std::vectorautolinkpaddle::Tensorautolink(arg.size()));
  }
  std::string op_name = "abs_grad";
  auto need_skip = paddle::prim::StaticCompositeContext::Instance().CheckSkipCompOps(op_name);
  if (paddle::prim::StaticCompositeContext::Instance().IsBwdPrimEnabled() && !need_skip) {
    FLAGS_tensor_operants_mode = "static";
    VLOG(4) << "Call Pir Decomposed backward op abs_grad";
    paddle::Tensor* x_grad = !stop_gradients[0][0] ? &vjp_res[0][0] : nullptr;
    details::abs_grad<LazyTensor>(x, out_grad, x_grad);
  } else {
    auto op_res = backend::abs_grad<LazyTensor>(x, out_grad);
    vjp_res[0][0] = op_res;
    vjp_res = ConstructVjpResultByStopGradients(vjp_res, stop_gradients);
  }
  return vjp_res;
}
```


#### 5.2.2 检查日志
- 前向拆解
配置 `export GLOG_vmodule=op_decomp=4`，用来打印 `op_decomp.cc`文件中对应算子的拆解规则函数 `log -- "Decomp call flatten's decomp interface begin"`
```
// /mnt/Paddle/build/paddle/fluid/pir/dialect/operator/ir/op_decomp.cc

std::vector<std::vectorautolinkpir::Valueautolink> FlattenOp::Decomp(pir::Operation* op) {
  VLOG(4) << "Decomp call flatten's decomp interface begin";
  FlattenOp op_obj = op->dyn_cast<FlattenOp>();
  (void)op_obj;
  ......
  }
```
- 反向拆解
配置 `export GLOG_vmodule=generated_vjp=4`，用来打印 `generated_vjp.cc`文件中对应算子的拆解规则函数 `log -- "Call Pir Decomposed backward op abs_grad"`
```
// /mnt/Paddle/build/paddle/fluid/primitive/rule/vjp/generated/generated_vjp.cc

std::vector<std::vectorautolinkpaddle::Tensorautolink> abs_vjp(const Tensor& x, const Tensor& out_grad, const std::vector<std::vector<bool>>& stop_gradients) {
......
  std::string op_name = "abs_grad";
  auto need_skip = paddle::prim::StaticCompositeContext::Instance().CheckSkipCompOps(op_name);
  if (paddle::prim::StaticCompositeContext::Instance().IsBwdPrimEnabled() && !need_skip) {
    FLAGS_tensor_operants_mode = "static";
    VLOG(4) << "Call Pir Decomposed backward op abs_grad";
    ......
  } else {
    ......
  }
  return vjp_res;
}
```
