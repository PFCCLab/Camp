### å§“å

ç”°å·

### å®ä¹ é¡¹ç›®

PIR åŠ¨è½¬é™ç»„ä»¶å»ºè®¾ä¸å•æµ‹éªŒè¯æ¨å…¨

### æœ¬å‘¨å·¥ä½œ

1. PIR åŠ¨è½¬é™ç»„ä»¶å•æµ‹é—®é¢˜æ‘¸åº•æ”¶å°¾

æ¥ä¸‹æ¥å‡ å‘¨ä¸»è¦åšé—®é¢˜ä¿®å¤éƒ¨åˆ†

ç›¸å…³pr: 

* [#59120](https://github.com/PaddlePaddle/Paddle/pull/59120)
* [#59232](https://github.com/PaddlePaddle/Paddle/pull/59232)
* [#59276](https://github.com/PaddlePaddle/Paddle/pull/59276)
* [#59314](https://github.com/PaddlePaddle/Paddle/pull/59314)
* [#59378](https://github.com/PaddlePaddle/Paddle/pull/59378)
* [#59517](https://github.com/PaddlePaddle/Paddle/pull/59517)
* [#59546](https://github.com/PaddlePaddle/Paddle/pull/59546)
* [#59569](https://github.com/PaddlePaddle/Paddle/pull/59569)

é‡åˆ°çš„ä¸€äº›é—®é¢˜:

* `cuda api` åˆ‡æ¢ä¸ç”Ÿæ•ˆ

åœ¨ [#59300](https://github.com/PaddlePaddle/Paddle/pull/59300) ä¸‹é€‚é…äº† `OpResult.cpu()` å’Œ `OpResult.cuda()` æ–¹æ³• (è¡¥å……è¯´æ˜: åœ¨[#59565](https://github.com/PaddlePaddle/Paddle/pull/59565) pr ä¸­å·²ç»Ÿä¸€ä¸º `Value`)

ä½†æ˜¯å† `test_tensor_memcpy_on_cpu` å•æµ‹ä¸­å‘ç°æ— æ³•ä» cpu åˆ‡æ¢ä¸º cuda, ä¸‹é¢æ˜¯ç²¾ç®€åçš„å¤ç°å•æµ‹

```python
def tensor_copy_to_cuda(x):
    x = paddle.to_tensor(x)
    y = x.cuda()
    return y

class TestTensorCopyToCUDAOnDefaultCPU(Dy2StTestBase):
    def _run(self, to_static):
        x1 = paddle.ones([1, 2, 3])
        x2 = paddle.jit.to_static(tensor_copy_to_cuda)(x1)
        return x1.place, x2.place

    @test_pir_only
    @test_sot_only
    def test_tensor_cuda_on_default_cpu(self):
        if not paddle.is_compiled_with_cuda():
            return

        paddle.framework._set_expected_place(paddle.CPUPlace())
        static_x1_place, static_place = self._run()
        self.assertTrue(static_x1_place.is_cpu_place())
        self.assertTrue(static_place.is_gpu_place())
```

åˆ†æ GLOG:
```bash
pir_interpreter.cc:1259 New Executor is Running ...
interpreter_util.cc:1262 -----------------------------
interpreter_util.cc:1264  (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"_jst.0.args.0",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[1,2,3],stop_gradient:[true]} : () -> undefined_tensor<1x2x3xf32>
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.data, OpInfo: ptr=0x47f2100].
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.data, OpInfo: ptr=0x47f2100].
interpreter_util.cc:1370 Value   : (   [0x81e4bf0]) = pd_op.data()
interpreter_util.cc:1371 Variable: (out[0x81e4e00]) = pd_op.data()
interpreter_util.cc:1262 -----------------------------
interpreter_util.cc:1264  (%0) = "memcpy(phi_kernel)" (%1) {dst_place_type:(Int32)1,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy",op_name:"pd_op.memcpy",stop_gradient:[true]} : (undefined_tensor<1x2x3xf32>) -> gpu_tensor<1x2x3xf32>
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.memcpy, OpInfo: ptr=0x7402b60].
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.memcpy, OpInfo: ptr=0x7402b60].
interpreter_util.cc:1370 Value   : (   [0x4c2ae00]) = pd_op.memcpy( [0x81e4bf0])
interpreter_util.cc:1371 Variable: (out[0x8202a80]) = pd_op.memcpy(x[0x81e4e00])
interpreter_util.cc:1262 -----------------------------
interpreter_util.cc:1264  (%0) = "memcpy_d2h(phi_kernel)" (%1) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<1x2x3xf32>) -> cpu_tensor<1x2x3xf32>
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.memcpy_d2h, OpInfo: ptr=0x7402d50].
ir_context.cc:117 Found a cached OpInfo of: [name=pd_op.memcpy_d2h, OpInfo: ptr=0x7402d50].
interpreter_util.cc:1370 Value   : (   [0x81e5660]) = pd_op.memcpy_d2h( [0x4c2ae00])
interpreter_util.cc:1371 Variable: (out[0x8202850]) = pd_op.memcpy_d2h(x[0x8202a80])
interpreter_util.cc:1262 -----------------------------
interpreter_util.cc:1264  () = "builtin.set_parameter" (%0) {parameter_name:"output_0"} : (cpu_tensor<1x2x3xf32>) -> 
ir_context.cc:117 Found a cached OpInfo of: [name=builtin.set_parameter, OpInfo: ptr=0x4b75358].
ir_context.cc:117 Found a cached OpInfo of: [name=builtin.set_parameter, OpInfo: ptr=0x4b75358].
interpreter_util.cc:1370 Value   : () = builtin.set_parameter(        [0x81e5660])
interpreter_util.cc:1371 Variable: () = builtin.set_parameter(output_0[0x8202850])
pir_interpreter.cc:1260 value info of interpretercore 0x81e77a0
```

å¯ä»¥çœ‹åˆ°æ‰§è¡Œå™¨æ‰§è¡Œçš„op, è§‚å¯Ÿopå¯ä»¥å‘ç°åœ¨æ‰§è¡Œ`memcpy`ååˆæ‰§è¡Œäº†`memcpy_d2h`, è€Œæ­¤æ—¶`dst_place_type`å‚æ•°çš„å€¼ä¸ºé»˜è®¤çš„0, æ‰€ä»¥åˆè¢«æ‹·è´å›äº†cpu.

tensotå­˜åœ¨è®¾å¤‡å›¾:

`undefined(cpu)` -> `GPU` -> `CPU`

å¯¹åº” op é¡ºåº:

`data` -> `memcpy` -> `memcpy_d2h`


* `paddle.jit.enable_to_static` æ³„æ¼é—®é¢˜

ç²¾ç®€å¤ç°demo:
```python
def run_lstm():
    paddle.jit.enable_to_static(OFF)
    net = paddle.jit.to_static(Net())

def save_in_eval():
    net = paddle.jit.to_static(Net()) # to_static ä¸ç”Ÿæ•ˆ

```

ç”±äº`enable_to_static`æ˜¯å…¨å±€çš„, æ‰€ä»¥å½“`run_lstm`å‡½æ•°ç»“æŸäº†ä¼šå¯¼è‡´`enable_to_static`æ³„æ¼ã€‚

ä¿®å¤æ–¹æ¡ˆ, ç›¸å½“äºç»™å®ƒåŠ äº†ä¸ªä½œç”¨åŸŸ:
```python
@contextmanager
def enable_to_static_guard(flag: bool):
    program_translator = paddle.jit.api.ProgramTranslator()
    original_flag_value = program_translator.enable_to_static
    program_translator.enable(flag)
    try:
        yield
    finally:
        program_translator.enable(original_flag_value)
```

ä¿®å¤pr:
* [#59670](https://github.com/PaddlePaddle/Paddle/pull/59670)

tracking issue:
* [#59684](https://github.com/PaddlePaddle/Paddle/issues/59684)

1. é€‚é…`OpResult.cpu()` and `OpResult.cuda()` 

pr: [#59300](https://github.com/PaddlePaddle/Paddle/pull/59300)

### ä¸‹å‘¨å·¥ä½œ

1. PIR åŠ¨è½¬é™ç»„ä»¶å•æµ‹é—®é¢˜ä¿®å¤
2. PIR API ä»¥åŠåŠ¨è½¬é™æœ€ç»ˆæ€é€‚é…


### å¯¼å¸ˆç‚¹è¯„

PIR ç†æƒ³æ€æ¨è¿›è¿…é€Ÿï¼Œç›®å‰ä¸€æœŸæ‘¸åº•å·²ç»åŸºæœ¬å®Œæˆï¼Œæ¥ä¸‹æ¥äºŒæœŸå¯ä»¥æŠ•å…¥åˆ°é—®é¢˜ä¿®å¤åŠç›¸å…³æœºåˆ¶å»ºè®¾ä¹‹ä¸­ï¼ŒLGTMeow ğŸ¾

