### 姓名
何咏哲

### 实习项目
全自动并行架构升级

### 本周工作

1. **讨论原有全自动并行架构的不足**
   
    * 原本的分布式训练是先将单卡的静态图切成分布式的图，切完再用cost model，切图的操作很耗时，为分布式训练策略的搜索带来了巨大的开销
    * 上一期集训营中为全自动并行架构构建了一个显存模型，该显存模型包括了tp、mp、pp、vpp、sp等维度，但是对于sharding和recompute的考虑还不够

2. **制定后续研究目标**

    * 采用单卡的图直接推算分布式的图，避免反复切图带来的开销
    * 完善原本的cost model，进一步包括sharding和recompute的过程
    * 将全自动并行架构由同构集群扩展到异构集群下

3. **考虑同构到异构的扩展**

    * 最重要的是保证训练过程中不会引发OOM错误，其次才是在这个基础上保证训练效率
    * 由于pp和vpp的引入，流水线中各个stage之间的显存消耗并不均衡，因此通过显存模型可以将占用显存多的（一般是stage 0）优先放置在显存大的设备上
    * 原本的显存模型是建立在同构集群上的，面向OOM错误，因此仅仅考虑了峰值显存，而扩展到异构集群上时就需要考虑各种并行维度的切分是否均衡的问题
    * 进一步的，在搜索并行维度时也要根据集群的硬件配置选择切分方式，而非简单地平均切分


4. **问题疑惑与解答**

    * 大模型训练需要花费多长时间？

      答：计算方法是数据量除以吞吐。对于大模型来说，比如llama 7b，一般只过一遍数据，也就是epoch为1。

      千卡规模下，7b、13b大概需要七八天。通常会在训练前进行一个预估，比如拿两台机器算总吞吐，假设用16卡预估64卡，那sharding维度就是4，吞吐的缩放比例是4，即理论上限是4倍吞吐，但实际过程中往往还存在一个折损，可能乘以0.8、0.9，并且这种损耗是递减的，放缩的规模越大，折损越严重，但是折损率的下降越来越慢。


    * 大模型的效果来源？

      答：模型效果来自两个方面，一个是规模，一个是数据规模。其实提升主要是来自数据。




### 下周工作

1. 完善原本的cost model，进一步包括sharding和recompute的过程

### 导师点评
本周明确了项目后续的具体工作，并在同构到异构的扩展方向提出了一些有建设性的想法，该工作正按计划稳步推进中。
